optimizations:
    executing training leads to HDD usage. why? and does S5 does the same? everything should be on the ram


todo:
S5
    choose what is possible, make the possibilities callable
    rng, do I need it?
learner
    saving & loading: model & optimizer state
    checkpointing
    prediction & deviation vs. mean & std (direct vs gauss)
Crypto
    binance vs bybit data
    maybe pretraining with finetuning
    causality check: evaluate and compare last timestep
    compare prediction for different input lengths
